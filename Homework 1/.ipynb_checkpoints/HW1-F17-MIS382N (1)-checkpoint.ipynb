{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align: center;\">MIS 382N: ADVANCED PREDICTIVE MODELING - MSBA</p>\n",
    "# <p style=\"text-align: center;\">Assignment 1</p>\n",
    "## <p style=\"text-align: center;\">Total points: 75</p>\n",
    "## <p style=\"text-align: center;\">Due: Tuesday, September 13 submitted via Canvas by 11:59 p</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTEID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group.  \n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Applications of machine learning (10 pts)\n",
    "\n",
    "Read the [article](http://www.datasciencecentral.com/profiles/blogs/20-data-science-systems-used-by-amazon-to-operate-its-business) \"21 data science systems used by Amazon to operate its business\" and pick any two of the data science systems used by Amazon according to this blog.\n",
    "\n",
    "(5 pts each) For each of these two system you have chosen:\n",
    "\n",
    "What kind of machine learning problem is involved (e.g. classification, regression, clustering, outlier detection,...)? Speculate on what kind of data may be needed and how the results can be useful to the company.\n",
    "\n",
    "\n",
    "## Answer\n",
    "Supply chain optimization (I). Sites selection for warehouses to minimize distribution costs (proximity to vendors, balanced against proximity to consumers). How many warehouses are needed, and what capacity each of them should have. \n",
    "\n",
    "The ideal data would be demographic\\orders data on both the vendors and nearby population. Amazon would need to know the order volume of nearby populations along with projected growth which would be a forecasting problem. Also Amazon would need to compare that to vendor/transportation data to see what the optimal placement of warehouses would be, and how much capacity they're likely to have. The results from this analysis would increase efficiency in delivery time, and an increase in margins by decrease the costs associated with transportation. \n",
    "\n",
    "\n",
    "Fake reviews detection. They still have tons of progress to make in this area: at least categorizing users would be a first step, so that buyers know what kind of user produced a specific review; then relevancy algorithms must be used to assess how relevant a review is for a specific product, knowing that most likes and stars assigned by users are biased - partly because most normal people don't have time or interest to write a review. Indeed, fake reviews is a lucrative business taking advantages of inefficiencies in platforms such as Amazon. The best solution is to remove user-generated reviews and replace them, for each product, by number of sales over the last 30 days.\n",
    "\n",
    "The data needed for this problem would be reviews on products, possibly, if available, data that turks have already went through on a sample data set that has fake reviews in it. This data would be used as a training set for a classification model that would learn to predict fake reviews. This model would look at the attributes of the real reviews and see if there are differences between the fake reviews and real reviews. Depending on how accurate the model is at detecting fake reviews, it would provide enormous value in parsing down the reviews which need inspection to see if they're fake or not. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Maximum likelihood estimate (10 pts)\n",
    "\n",
    "Suppose a manager at an internet sales company wants to estimate how fast his salesperson is generating successful leads. Instead of recording the time for each lead, the time taken to generate the next 5 leads are recorded, i.e., there is one recording (denoting the elapsed time) for every 5 consecutive leads. For a specific salesperson, the time intervals recorded are {1,3,1.5,4,2,7,1.2,2,4,3.1} hours. \n",
    "\n",
    "A statistician suggests that if these time intervals are assumed to arise by i.i.d. sampling from the following distribution:\n",
    "$$ p(t) = \\frac{1}{C \\times \\theta^{5}}t^{4}exp^{-\\frac{t}{\\theta}},$$\n",
    "(where C is a normalizing constant). Therefore, if $\\theta$ can be estimated, then he can provide detailed information\n",
    "about the lead generation process, including average rates, variances etc.\n",
    "\n",
    "Find the Maximum Likelihood estimate for $\\theta$ based on the recorded observations.\n",
    "\n",
    "\n",
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Multiple Linear Regression in Python (25 pts)\n",
    "\n",
    "Use the following code to import the boston housing dataset and linear models in python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "features=boston.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset information can be found [here](http://scikit-learn.org/stable/datasets/index.html#boston-house-prices-dataset).\n",
    "\n",
    "a. (3 pts) Print the shape (number of rows and columns) of the feature matrix, and print the first 5 rows.\n",
    "\n",
    "b.  (6 pts) Using ordinary least squares, fit a multiple linear regression (MLR) on all the feature variables using the entire dataset (506 rows). Report the regression coefficient of each input feature and evaluate the model using mean squared error (MSE).  Example of ordinary least squares in Python is shown in Section 1.1.1 of http://scikit-learn.org/stable/modules/linear_model.html.\n",
    "\n",
    "c.  (6 pts) Split the data into a training set and a test set.  Use the first 400 rows for training set and remaining rows for test set.  Fit an MLR using the training set.  Evaluate the trained model using the training set and the test set, respectively.  Compare the two MSE values thus obtained.\n",
    "\n",
    "d.  (6 pts) Do you think your MLR model is reasonable for this problem? You may look at the distribution of residuals to provide an informed answer.\n",
    "\n",
    "e. (5 pts) Use the following code to add new features to the dataset.  You should have 26 variables now.  Note that this code adds one squared term for each variable; in practice one may introduce only a few terms based on domain knowledge or experimentation.  Repeat (c) and report the MSE values of the training set and the test set, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X, np.square(X)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deeks\\Anaconda2\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "# Special packages\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>392.52</td>\n",
       "      <td>20.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.50</td>\n",
       "      <td>15.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.02</td>\n",
       "      <td>10.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.05393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.935</td>\n",
       "      <td>29.3</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.85</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.75</td>\n",
       "      <td>14.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>288.99</td>\n",
       "      <td>11.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.25179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.570</td>\n",
       "      <td>98.1</td>\n",
       "      <td>3.7979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.57</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.85204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.965</td>\n",
       "      <td>89.2</td>\n",
       "      <td>4.0123</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>392.53</td>\n",
       "      <td>13.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.98843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.54</td>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.75026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.924</td>\n",
       "      <td>94.1</td>\n",
       "      <td>4.3996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.33</td>\n",
       "      <td>16.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>303.42</td>\n",
       "      <td>16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.67191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>90.3</td>\n",
       "      <td>4.6820</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.88</td>\n",
       "      <td>14.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.95577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.047</td>\n",
       "      <td>88.8</td>\n",
       "      <td>4.4534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>306.38</td>\n",
       "      <td>17.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.77299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.495</td>\n",
       "      <td>94.4</td>\n",
       "      <td>4.4547</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>387.94</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.674</td>\n",
       "      <td>87.3</td>\n",
       "      <td>4.2390</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.23</td>\n",
       "      <td>11.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4.87141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.484</td>\n",
       "      <td>93.6</td>\n",
       "      <td>2.3053</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.21</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>10.23300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.185</td>\n",
       "      <td>96.7</td>\n",
       "      <td>2.1705</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>379.70</td>\n",
       "      <td>18.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>14.33370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.229</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.9512</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>383.32</td>\n",
       "      <td>13.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5.82401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.242</td>\n",
       "      <td>64.7</td>\n",
       "      <td>3.4242</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>10.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5.70818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.750</td>\n",
       "      <td>74.9</td>\n",
       "      <td>3.3317</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>393.07</td>\n",
       "      <td>7.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>5.73116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>7.061</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.4106</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.28</td>\n",
       "      <td>7.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2.81838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>5.762</td>\n",
       "      <td>40.3</td>\n",
       "      <td>4.0983</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.92</td>\n",
       "      <td>10.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2.37857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.871</td>\n",
       "      <td>41.9</td>\n",
       "      <td>3.7240</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>370.73</td>\n",
       "      <td>13.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3.67367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.312</td>\n",
       "      <td>51.9</td>\n",
       "      <td>3.9917</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.62</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>5.69175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.114</td>\n",
       "      <td>79.8</td>\n",
       "      <td>3.5459</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.68</td>\n",
       "      <td>14.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4.83567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.905</td>\n",
       "      <td>53.2</td>\n",
       "      <td>3.1523</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.22</td>\n",
       "      <td>11.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.15086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.454</td>\n",
       "      <td>92.7</td>\n",
       "      <td>1.8209</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>395.09</td>\n",
       "      <td>18.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.18337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.414</td>\n",
       "      <td>98.3</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>344.05</td>\n",
       "      <td>23.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.20746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.093</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.8226</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>318.43</td>\n",
       "      <td>29.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.11132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>83.5</td>\n",
       "      <td>2.1099</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.17331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.707</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.27957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.926</td>\n",
       "      <td>42.6</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.17899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.670</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>393.29</td>\n",
       "      <td>17.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.28960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.390</td>\n",
       "      <td>72.9</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.26838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.794</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.8927</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.23912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.019</td>\n",
       "      <td>65.3</td>\n",
       "      <td>2.4091</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.17783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.569</td>\n",
       "      <td>73.5</td>\n",
       "      <td>2.3999</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>395.77</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2    3      4      5      6       7     8      9   \\\n",
       "0     0.00632  18.0   2.31  0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n",
       "1     0.02731   0.0   7.07  0.0  0.469  6.421   78.9  4.9671   2.0  242.0   \n",
       "2     0.02729   0.0   7.07  0.0  0.469  7.185   61.1  4.9671   2.0  242.0   \n",
       "3     0.03237   0.0   2.18  0.0  0.458  6.998   45.8  6.0622   3.0  222.0   \n",
       "4     0.06905   0.0   2.18  0.0  0.458  7.147   54.2  6.0622   3.0  222.0   \n",
       "5     0.02985   0.0   2.18  0.0  0.458  6.430   58.7  6.0622   3.0  222.0   \n",
       "6     0.08829  12.5   7.87  0.0  0.524  6.012   66.6  5.5605   5.0  311.0   \n",
       "7     0.14455  12.5   7.87  0.0  0.524  6.172   96.1  5.9505   5.0  311.0   \n",
       "8     0.21124  12.5   7.87  0.0  0.524  5.631  100.0  6.0821   5.0  311.0   \n",
       "9     0.17004  12.5   7.87  0.0  0.524  6.004   85.9  6.5921   5.0  311.0   \n",
       "10    0.22489  12.5   7.87  0.0  0.524  6.377   94.3  6.3467   5.0  311.0   \n",
       "11    0.11747  12.5   7.87  0.0  0.524  6.009   82.9  6.2267   5.0  311.0   \n",
       "12    0.09378  12.5   7.87  0.0  0.524  5.889   39.0  5.4509   5.0  311.0   \n",
       "13    0.62976   0.0   8.14  0.0  0.538  5.949   61.8  4.7075   4.0  307.0   \n",
       "14    0.63796   0.0   8.14  0.0  0.538  6.096   84.5  4.4619   4.0  307.0   \n",
       "15    0.62739   0.0   8.14  0.0  0.538  5.834   56.5  4.4986   4.0  307.0   \n",
       "16    1.05393   0.0   8.14  0.0  0.538  5.935   29.3  4.4986   4.0  307.0   \n",
       "17    0.78420   0.0   8.14  0.0  0.538  5.990   81.7  4.2579   4.0  307.0   \n",
       "18    0.80271   0.0   8.14  0.0  0.538  5.456   36.6  3.7965   4.0  307.0   \n",
       "19    0.72580   0.0   8.14  0.0  0.538  5.727   69.5  3.7965   4.0  307.0   \n",
       "20    1.25179   0.0   8.14  0.0  0.538  5.570   98.1  3.7979   4.0  307.0   \n",
       "21    0.85204   0.0   8.14  0.0  0.538  5.965   89.2  4.0123   4.0  307.0   \n",
       "22    1.23247   0.0   8.14  0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "23    0.98843   0.0   8.14  0.0  0.538  5.813  100.0  4.0952   4.0  307.0   \n",
       "24    0.75026   0.0   8.14  0.0  0.538  5.924   94.1  4.3996   4.0  307.0   \n",
       "25    0.84054   0.0   8.14  0.0  0.538  5.599   85.7  4.4546   4.0  307.0   \n",
       "26    0.67191   0.0   8.14  0.0  0.538  5.813   90.3  4.6820   4.0  307.0   \n",
       "27    0.95577   0.0   8.14  0.0  0.538  6.047   88.8  4.4534   4.0  307.0   \n",
       "28    0.77299   0.0   8.14  0.0  0.538  6.495   94.4  4.4547   4.0  307.0   \n",
       "29    1.00245   0.0   8.14  0.0  0.538  6.674   87.3  4.2390   4.0  307.0   \n",
       "..        ...   ...    ...  ...    ...    ...    ...     ...   ...    ...   \n",
       "476   4.87141   0.0  18.10  0.0  0.614  6.484   93.6  2.3053  24.0  666.0   \n",
       "477  15.02340   0.0  18.10  0.0  0.614  5.304   97.3  2.1007  24.0  666.0   \n",
       "478  10.23300   0.0  18.10  0.0  0.614  6.185   96.7  2.1705  24.0  666.0   \n",
       "479  14.33370   0.0  18.10  0.0  0.614  6.229   88.0  1.9512  24.0  666.0   \n",
       "480   5.82401   0.0  18.10  0.0  0.532  6.242   64.7  3.4242  24.0  666.0   \n",
       "481   5.70818   0.0  18.10  0.0  0.532  6.750   74.9  3.3317  24.0  666.0   \n",
       "482   5.73116   0.0  18.10  0.0  0.532  7.061   77.0  3.4106  24.0  666.0   \n",
       "483   2.81838   0.0  18.10  0.0  0.532  5.762   40.3  4.0983  24.0  666.0   \n",
       "484   2.37857   0.0  18.10  0.0  0.583  5.871   41.9  3.7240  24.0  666.0   \n",
       "485   3.67367   0.0  18.10  0.0  0.583  6.312   51.9  3.9917  24.0  666.0   \n",
       "486   5.69175   0.0  18.10  0.0  0.583  6.114   79.8  3.5459  24.0  666.0   \n",
       "487   4.83567   0.0  18.10  0.0  0.583  5.905   53.2  3.1523  24.0  666.0   \n",
       "488   0.15086   0.0  27.74  0.0  0.609  5.454   92.7  1.8209   4.0  711.0   \n",
       "489   0.18337   0.0  27.74  0.0  0.609  5.414   98.3  1.7554   4.0  711.0   \n",
       "490   0.20746   0.0  27.74  0.0  0.609  5.093   98.0  1.8226   4.0  711.0   \n",
       "491   0.10574   0.0  27.74  0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
       "492   0.11132   0.0  27.74  0.0  0.609  5.983   83.5  2.1099   4.0  711.0   \n",
       "493   0.17331   0.0   9.69  0.0  0.585  5.707   54.0  2.3817   6.0  391.0   \n",
       "494   0.27957   0.0   9.69  0.0  0.585  5.926   42.6  2.3817   6.0  391.0   \n",
       "495   0.17899   0.0   9.69  0.0  0.585  5.670   28.8  2.7986   6.0  391.0   \n",
       "496   0.28960   0.0   9.69  0.0  0.585  5.390   72.9  2.7986   6.0  391.0   \n",
       "497   0.26838   0.0   9.69  0.0  0.585  5.794   70.6  2.8927   6.0  391.0   \n",
       "498   0.23912   0.0   9.69  0.0  0.585  6.019   65.3  2.4091   6.0  391.0   \n",
       "499   0.17783   0.0   9.69  0.0  0.585  5.569   73.5  2.3999   6.0  391.0   \n",
       "500   0.22438   0.0   9.69  0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n",
       "501   0.06263   0.0  11.93  0.0  0.573  6.593   69.1  2.4786   1.0  273.0   \n",
       "502   0.04527   0.0  11.93  0.0  0.573  6.120   76.7  2.2875   1.0  273.0   \n",
       "503   0.06076   0.0  11.93  0.0  0.573  6.976   91.0  2.1675   1.0  273.0   \n",
       "504   0.10959   0.0  11.93  0.0  0.573  6.794   89.3  2.3889   1.0  273.0   \n",
       "505   0.04741   0.0  11.93  0.0  0.573  6.030   80.8  2.5050   1.0  273.0   \n",
       "\n",
       "       10      11     12  \n",
       "0    15.3  396.90   4.98  \n",
       "1    17.8  396.90   9.14  \n",
       "2    17.8  392.83   4.03  \n",
       "3    18.7  394.63   2.94  \n",
       "4    18.7  396.90   5.33  \n",
       "5    18.7  394.12   5.21  \n",
       "6    15.2  395.60  12.43  \n",
       "7    15.2  396.90  19.15  \n",
       "8    15.2  386.63  29.93  \n",
       "9    15.2  386.71  17.10  \n",
       "10   15.2  392.52  20.45  \n",
       "11   15.2  396.90  13.27  \n",
       "12   15.2  390.50  15.71  \n",
       "13   21.0  396.90   8.26  \n",
       "14   21.0  380.02  10.26  \n",
       "15   21.0  395.62   8.47  \n",
       "16   21.0  386.85   6.58  \n",
       "17   21.0  386.75  14.67  \n",
       "18   21.0  288.99  11.69  \n",
       "19   21.0  390.95  11.28  \n",
       "20   21.0  376.57  21.02  \n",
       "21   21.0  392.53  13.83  \n",
       "22   21.0  396.90  18.72  \n",
       "23   21.0  394.54  19.88  \n",
       "24   21.0  394.33  16.30  \n",
       "25   21.0  303.42  16.51  \n",
       "26   21.0  376.88  14.81  \n",
       "27   21.0  306.38  17.28  \n",
       "28   21.0  387.94  12.80  \n",
       "29   21.0  380.23  11.98  \n",
       "..    ...     ...    ...  \n",
       "476  20.2  396.21  18.68  \n",
       "477  20.2  349.48  24.91  \n",
       "478  20.2  379.70  18.03  \n",
       "479  20.2  383.32  13.11  \n",
       "480  20.2  396.90  10.74  \n",
       "481  20.2  393.07   7.74  \n",
       "482  20.2  395.28   7.01  \n",
       "483  20.2  392.92  10.42  \n",
       "484  20.2  370.73  13.34  \n",
       "485  20.2  388.62  10.58  \n",
       "486  20.2  392.68  14.98  \n",
       "487  20.2  388.22  11.45  \n",
       "488  20.1  395.09  18.06  \n",
       "489  20.1  344.05  23.97  \n",
       "490  20.1  318.43  29.68  \n",
       "491  20.1  390.11  18.07  \n",
       "492  20.1  396.90  13.35  \n",
       "493  19.2  396.90  12.01  \n",
       "494  19.2  396.90  13.59  \n",
       "495  19.2  393.29  17.60  \n",
       "496  19.2  396.90  21.14  \n",
       "497  19.2  396.90  14.10  \n",
       "498  19.2  396.90  12.92  \n",
       "499  19.2  395.77  15.10  \n",
       "500  19.2  396.90  14.33  \n",
       "501  21.0  391.99   9.67  \n",
       "502  21.0  396.90   9.08  \n",
       "503  21.0  396.90   5.64  \n",
       "504  21.0  393.45   6.48  \n",
       "505  21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = np.empty(506)\n",
    "#x.fill(1)\n",
    "#X = np.insert(X,0,x, axis = 1)\n",
    "DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n',                  1\n",
      "0                 \n",
      "CRIM     -0.107171\n",
      "ZN        0.046395\n",
      "INDUS     0.020860\n",
      "CHAS      2.688561\n",
      "NOX     -17.795759\n",
      "RM        3.804752\n",
      "AGE       0.000751\n",
      "DIS      -1.475759\n",
      "RAD       0.305655\n",
      "TAX      -0.012329\n",
      "PTRATIO  -0.953464\n",
      "B         0.009393\n",
      "LSTAT    -0.525467)\n",
      "Mean squared error: 21.90\n",
      "Variance score: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X,y)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', DataFrame((zip(features, regr.coef_))).set_index(0))\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y,y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.491103280361983"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.intercept_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X[:400]\n",
    "y_train=y[:400]\n",
    "X_test=X[400:]\n",
    "y_test=y[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([  0.00000000e+00,  -1.91246374e-01,   4.42289967e-02,\n",
      "         5.52207977e-02,   1.71631351e+00,  -1.49957220e+01,\n",
      "         4.88773025e+00,   2.60921031e-03,  -1.29480799e+00,\n",
      "         4.84787214e-01,  -1.54006673e-02,  -8.08795026e-01,\n",
      "        -1.29230427e-03,  -5.17953791e-01]))\n",
      "Mean squared error: 38.16\n",
      "Variance score: -0.35\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test,y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resid=y_pred-y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x119f66610>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAENCAYAAAAVPvJNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a2a6b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred, resid)\n",
    "plt.xlabel('y_pred', fontsize=18)\n",
    "plt.ylabel('Residual', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X, np.square(X)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X[1:400]\n",
    "y_train=y[1:400]\n",
    "X_test=X[401:506]\n",
    "y_test=y[401:506]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([ -6.29858595e-01,  -4.45165189e-02,   1.19794162e-01,\n",
      "         1.12715814e+00,  -3.53735534e+01,  -1.70334797e+01,\n",
      "        -1.77939367e-02,  -2.46397289e+00,   6.33212274e-01,\n",
      "        -1.07058926e-01,  -6.13023162e+00,   4.17195544e-02,\n",
      "        -1.45158404e+00,   5.05473617e-03,   5.07111842e-04,\n",
      "        -4.40099663e-03,   1.12715811e+00,   8.70178640e+00,\n",
      "         1.60509628e+00,   2.85884612e-04,   1.34957549e-01,\n",
      "        -3.10265747e-02,   1.41835054e-04,   1.51177799e-01,\n",
      "        -7.52873183e-05,   2.73178550e-02]))\n",
      "Mean squared error: 32.14\n",
      "Variance score: -0.17\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test,y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x118c63b10>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFfCAYAAABTOoWkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nATssecXdphNNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1191dd7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resid=y_pred-y_test\n",
    "plt.scatter(y_pred, resid)\n",
    "plt.xlabel('y_pred', fontsize=18)\n",
    "plt.ylabel('Residual', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Ridge and Lasso Regression (25 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same boston data from before, in this question you will explore the application of Lasso and Ridge regression using sklearn package in Python. The following code will split the data into training and test set using [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) with **random state 20** and **test_size = 0.33**.  Note: lambda is called alpha in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "features=boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = np.concatenate((X, np.square(X)), axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.33, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Use sklearn.linear_model.Lasso and sklearn.linear_model.Ridge classes to do a [5-fold cross validation](http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py) using sklearn's [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html). For the sweep of the regularization parameter, we will look at a grid of values ranging from $\\lambda = 10^{10}$ to $\\lambda = 10^{-2}$. In Python, you can consider this range of values as follows:\n",
    "\n",
    "      import numpy as np\n",
    "\n",
    "      alphas =  10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "  Report the best chosen $\\lambda$ based on cross validation. The cross validation should happen on your training data using  average MSE as the scoring metric. (8pts)\n",
    "\n",
    "2) Run ridge and lasso for all of the alphas specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; the plots for different features for a method should be on the same plot (e.g. Fig 6.6 of JW). What do you qualitatively observe when value of the regularization parameter is changed? (7pts)\n",
    "\n",
    "3) Run least squares regression, ridge, and lasso on the training data. For ridge and lasso, use only the best regularization parameter. Report the prediction error (MSE) on the test data for each. (5pts)\n",
    "\n",
    "4) Run lasso again with cross validation using [sklearn.linear_model.LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). Set the cross validation parameters as follows:\n",
    "\n",
    "    LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "\n",
    "Report the best $\\lambda$ based on cross validation. Run lasso on the training data using the best $\\lambda$ and report the coefficeints for 26 variables. What do you observe from these coefficients? (5pts)\n",
    "\n",
    "## Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.289444</td>\n",
       "      <td>43.230625</td>\n",
       "      <td>4251.04</td>\n",
       "      <td>16.728100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87616.0</td>\n",
       "      <td>234.09</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>24.8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219961</td>\n",
       "      <td>41.229241</td>\n",
       "      <td>6225.21</td>\n",
       "      <td>24.672082</td>\n",
       "      <td>4.0</td>\n",
       "      <td>58564.0</td>\n",
       "      <td>316.84</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>83.5396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219961</td>\n",
       "      <td>51.624225</td>\n",
       "      <td>3733.21</td>\n",
       "      <td>24.672082</td>\n",
       "      <td>4.0</td>\n",
       "      <td>58564.0</td>\n",
       "      <td>316.84</td>\n",
       "      <td>154315.4089</td>\n",
       "      <td>16.2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209764</td>\n",
       "      <td>48.972004</td>\n",
       "      <td>2097.64</td>\n",
       "      <td>36.750269</td>\n",
       "      <td>9.0</td>\n",
       "      <td>49284.0</td>\n",
       "      <td>349.69</td>\n",
       "      <td>155732.8369</td>\n",
       "      <td>8.6436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209764</td>\n",
       "      <td>51.079609</td>\n",
       "      <td>2937.64</td>\n",
       "      <td>36.750269</td>\n",
       "      <td>9.0</td>\n",
       "      <td>49284.0</td>\n",
       "      <td>349.69</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>28.4089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4      5     6       7    8      9    ...     \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0   ...      \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0   ...      \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0   ...      \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0   ...      \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0   ...      \n",
       "\n",
       "    16        17         18       19         20   21       22      23  \\\n",
       "0  0.0  0.289444  43.230625  4251.04  16.728100  1.0  87616.0  234.09   \n",
       "1  0.0  0.219961  41.229241  6225.21  24.672082  4.0  58564.0  316.84   \n",
       "2  0.0  0.219961  51.624225  3733.21  24.672082  4.0  58564.0  316.84   \n",
       "3  0.0  0.209764  48.972004  2097.64  36.750269  9.0  49284.0  349.69   \n",
       "4  0.0  0.209764  51.079609  2937.64  36.750269  9.0  49284.0  349.69   \n",
       "\n",
       "            24       25  \n",
       "0  157529.6100  24.8004  \n",
       "1  157529.6100  83.5396  \n",
       "2  154315.4089  16.2409  \n",
       "3  155732.8369   8.6436  \n",
       "4  157529.6100  28.4089  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X_train_scaled = scale(X_train, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "X_test_scaled = scale(X_test, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lasso setup for cross validating the shrinkage parameter with K_fold cv.\n",
    "lasso = Lasso(random_state=0)\n",
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "n_folds = 5\n",
    "\n",
    "# Uses function gridsearch to iterate the lasso model over the k_folds\n",
    "clf = GridSearchCV(lasso, tuned_parameters, cv=n_folds, refit=False,scoring='neg_mean_squared_error')#refit needs to be true?? need to standardize x's??\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "#stores the scores of the cross validation\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "scores_std = clf.cv_results_['std_test_score']\n",
    "\n",
    "########\n",
    "# CODE NOT USED \n",
    "########\n",
    "#plt.figure().set_size_inches(8, 6)\n",
    "#plt.semilogx(alphas, scores)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "#std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "#plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "#plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "#plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "#plt.ylabel('CV score +/- std error')\n",
    "#plt.xlabel('alpha')\n",
    "#plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "#plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.015269277544167062}\n"
     ]
    }
   ],
   "source": [
    "lasso_param=clf.best_params_\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The optimal lambda for the cross validated lasso regression is the alpha show above. The lambda is relatively small meaning that the model needs to be more complex to get the optimal MSE. We chose to normalize the data because the data were all of different magnitudes/units and needed to be normalized so the appropriate lambda could be chosen for all the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge = Ridge(random_state=0,normalize=True)\n",
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "n_folds = 5\n",
    "\n",
    "clf = GridSearchCV(ridge, tuned_parameters, cv=n_folds, refit=False,scoring='neg_mean_squared_error')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "scores_std = clf.cv_results_['std_test_score']\n",
    "#plt.figure().set_size_inches(8, 6)\n",
    "#plt.semilogx(alphas, scores)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "#std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "#plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "#plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "#plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "#plt.ylabel('CV score +/- std error')\n",
    "#plt.xlabel('alpha')\n",
    "#plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "#plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0050000000000000001}\n"
     ]
    }
   ],
   "source": [
    "ridge_param=clf.best_params_\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The optimal lambda for the cross validated Ridge regression is the alpha show above. The lambda is the same as the lasso regression.  We chose to normalize the data because the data were all of different magnitudes/units and needed to be normalized so the appropriate lambda could be chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xdb412e8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEOCAYAAACXX1DeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHiNJREFUeJzt3X98XHWd7/HXZyYz+f2jTdKWhqZpaIuU3xBQLL/Kjwvu\nhUW5q4s/UETtlcVF8cfe9ccq+7hX9IF77+rKChbBB+6iCyKKIsIu8kPRirSilFqgQJM2JW3StE2a\nXzOTme/9YyY1pslkJpnJmcx5Px+PeSRnzsk5n2+S5t3v95zzPeacQ0REZCoBrwsQEZHCpqAQEZG0\nFBQiIpKWgkJERNJSUIiISFoKChERSUtBISIiaSkoREQkLQWFiIikpaAQEZG0SrwuIBcaGhpcS0uL\n12WIiMwrmzdv3ueca5xuu6IIipaWFjZt2uR1GSIi84qZdWSynYaeREQkLQWFiIikpaAQEZG0FBQi\nIpKWgkJERNJSUIiISFpFcXlsvkW7BiHhCC2qwELKVhHxFwXFNOJ9EbpvfQ7iDgxKGsqpbFtC1TlN\nWMC8Lk9EJO8UFNMY2NgFCUfdlSuJH4wQbe+n72c7GHnlAAvfcSzB6rDXJYqI5JWCIo1ENM7gb7so\nW1NP1ZlHAeCcY/C3ezj4k9fY+7XfUf/u4yhdUetxpSIi+aMB9zSGnusmMTRK9dqmw++ZGVVvPIrF\nHzkFKw2y/76XcKMJD6sUEckvBcUUXMIx8PRuQk1VhFfUHLE+tKSSur88hviBCIOb93pQoYjI3FBQ\nTCGy/QCjPcNUrV2K2eQnrctWLyDcXM2hx3fiYupViEhx8vU5ChdLMHpghMRAjMRQjMTQKBhYKMDA\nxi4C1SEqTpp6Bl4zo+bi5ey78wUGn91D1ZuXzmH1IiJzw9dBEWnfz747t025vuaSFqwkfaerdGUd\n4RU19D+xi8ozFmOhYK7LFBHxlK+DIt73OsPP3oGLDuCihyCYILS0iXBLK+EVK6hsO3XafZgZtRe3\n0LPheQZ+00X1OUfPQeUiInPH10FRtrKZxZ96N/GDB4kfPMjo/l6i7e0M/+4XHHroXhJ9u1nymc9M\nu5/S1lrCK2oZ2NhF1dlNU57TEBGZj3wdFMG6OmouvWTSdZ0f/Rj9P3mIxZ/8JBae/qa6ylMXceCB\n7cS6Bgkvrcp1qSIintFVT1Oou/JtxA8c4NBTT2W0fdnx9RCA4S378lyZiMjcUlBMoXLtWkoaG+n7\n4Y8y2j5YGaK0tY7hLftwzuW5OhGRueProafJOJcgFjtANLqP4HtOo/vXjzC67auMlgwRiXYTjfQQ\nT0SABM7FwTkcCXAJEisdrtex+7cNhCpqCJXUEgrVEQrVEQ43Eg43Ulq6iLKypZSUVHvdVBGRjPg6\nKIaG2mnvuI1otIdoZB+RaA+xWG8yAABWJV8Hu75OIFBGaXgR4dIGSkqqMAwsgFkQMMwCJEIxhnv2\nEhvoI8Y+YrE+YrGDOBc94tjBYBXl5UdTXr6civLlVFS0UlV9HFWVqwgESuf0+yAiko6vgyKRiLJ/\n/9Op/+kvprr6eMLhhnGvRrr/1xcJ9o7S+v2fEAhMP1LXs+l54ruiLPl4G5CcRDAeHyQa3Uc0uo9I\nZA8jkS5GRnYzPNzJ4OAr7Nv3xOEwMSuhqvJYFtafS2PDBdTUnJwKIxERb/g6KKqqVnP22l+l3+iC\nd7HnppuIbN1K+YknTrvP8hMbOPjgq8T2DhJaXImZUVJSRUlJFRUVLZN+jXNxhod3cWhgG4cObaWv\n73fs3LmBjo7bCIXqOWrJW2lqeicVFStm0EoRkdmxQj3xamaXAl8DgsC3nHNfnmrbtrY2t2nTprzU\nEe/v55Xz1wFQ99d/zcJr3kdo8eI020fp+tIz1FzYTM1Fy2d83Fisj97ep+jueYR9+36Oc6PU1b2R\nlpa/YeGCtbpXQ0Rmzcw2O+fapt2uEIPCkmMtLwMXA53As8A7nXN/nGz7fAYFQGT7dvZtuIP+hx+G\nQICFV19N40dvIFA6+bmE7m/+gdG9Q9S/Zw2lrbN/VkUk0kNX1/107r6HSKSLBXVv4phjPkVt7Smz\n3reI+Nd8D4qzgJucc5eklj8N4Jz70mTbzzQootE+dnXcQ23dydTWnUQolP5KpGjnbvbdfht99/+A\n0tWrWfqVWyg79tgjtov1DNF79x8Z3T9C3WWtVJ51VE56AIlEhN27v8eO9n8lFtvPggVvZtmya2io\nX4eZrnQWkezM96D4K+BS59wHU8tXA290zn1ksu1nGhQPfeMLvPTU5vFHJnlrSQAjkLyqiQAQxAim\nloOp7TLnUpu7sUMcXph8T1Z4PxIRKVShEB/9zu0z+tJMg2Lensw2s/XAeoDm5uYZ7SNUtpTqRBex\nUDU4ByRwjH2Mpz4mwMWTyy6BI8Lhv/KZSj2qIt3/+cfv0en0g4hkKBDP/x+MQg2K3cCycctHp947\nzDm3AdgAyR7FTA5yybX/E66daYl/8uijj7Jx40bOPfdcjjvuODZt2sTmzZtZsWIF69ato7m5mS2d\nfVx+69N84fI1vH/tzK5e6ujv4B9+9Q881/0c65at46o3XMXx9cdTW6pndotI/hRqUDwLrDKzFSQD\n4irgXd6WNLktW7awceNGzjzzTC644AIAurq6aG1t5b3vfe/h7e7e2E5FOMj/OD37acj3j+zn2y98\nm++9+D3CwTA3n30zl7VepiufRGROFGRQOOdGzewjwKMkL4+9yzm31eOyjrBnzx4efPBBmpubueSS\nP81C29fXx5IlSw4v7x+M8uM/vM472o6mpiyU+f4H93DvS/dyz7Z7iMQj/MWKv+Bjp32MxZVTX54r\nIpJrBRkUAM65h4GHva5jKr29vXz3u9+lvLyct7/97QSDybunR0dHGRwcpLb2T8NB9z67i+hogvee\n1TLtfvsifTzT9QwPvPIAG1/fSMIluLTlUq47+Tpa61rz1RwRkSkVbFAUsp6eHu6++24SiQRXX301\n1dV/uqy2v78f4HBQxBOOf/9NB2e11rN6cTXOOaKJKIOxQfYP76ejv4Md/Tt49eCrbNm3hY7+DgAW\nVyzmgyd+kLeufCvLqpcdWYSIyBwpyMtjs5XvG+7GjCZG+dwTn2Pjjo0kLEFlTSUxYkTiEUZGR3DO\nsSSyhDM6z+D55c9zoPIAI7E4/SNRKksNLE4sHmPUjR6x70Xlizi+4XhOajyJkxtP5rRFpxEMaI4n\nEcmfor881gs3PX4TP939U5a6paxctpLK8krKgmWUlZRRFiwDg+GOYWKdMeqrVtLTP8D+QxGqS0Nc\ncXwz4WCIcDBMZaiSipIKaktraalpYXnNcqrCeiqeiBQmBUWGbn38Vh7c/SAnRE/gtrffRl1d3Z+t\nH4qO8tRLPTzV9QvK2Mbjm89h6cJKPv7G5byjbRkLKqd/nKqISCFSUEwjHo9z9yN3c0f3HSwLLOOO\nd99BVUXyf/+xeIKnt+/jR7/fzX9u3ctwLM55ZftZHizlW+9/I+etaiQQ0CWsIjK/+ToodvYOcdtT\nrzAYiTMUHWUoGidcEqAiHKQiXEIZo3S0b2brgrsoK6nh+rav8mJ3lG17Onh6ew+/frWXQyOj1JaH\neOupTVx+0lG8unE/Q0MB1h27yOvmiYjkhK+DYiAyys+3dVNZWkJFOEh5KMhAZJSd+2IcHBymbyRC\nePlPCAYjHGy/lutf3A5sB6Cprpz/fuJRXHjcYs5b3Ui4JDlBx3OP9lNfX+9hq0REcsvXQbFmaQ3P\nfOZCBgYG2L9/P93d3Wzbto0dvTtwOF47fgfPJdr5xCn/yOkXX8hQdJThWJzl9ZW01FdMemd0X18f\nra2630FEioevg6Kzs5O7776bWCx2+L0FCxZw9tln81rNa/zgjz/g2hOu5ZqTr8xofyMjI0SjUWpq\navJVsojInPN1UNTW1nL66aezcOHCw68FCxbw+K7H+caT3+DsprO54dQbMt5fX1/f4f2KiBQLXwdF\ndXU1l1566Z+99/jOx/nkk59kTcMavnLuV7K66U1BISLFSI9FG+fJXU/yiac+wZr6Ndx+0e1Z3wSn\noBCRYqSgAJxzfP/l73Pjkzdy3MLjuP3i26kOp38s6mT6+/sJBAJUVekuaxEpHr4eegKIxCPc/MzN\nPLD9AdYuXcst590yo5CAZI+iurqaQED5KyLFw9dBsWdwDzc+cSMv9L7Ah078ENefcv2sJuLr6+vT\nsJOIFB1fB8VQbIju4W6+uu6rXNh84az319/fT1NTUw4qExEpHL4Oita6Vn525c8IB2c/YV8ikaCv\nr481a9bkoDIRkcLh+8H0XIQEwODgIIlEQkNPIlJ0fB8UuaJLY0WkWCkocmTsEaiavkNEio2CIkfU\noxCRYqWgyJG+vj5CoRDl5eVelyIiklMKihzp6+ujpqZm0qnHRUTmMwVFjgwMDOj8hIgUJQVFjoyM\njFBWVuZ1GSIiOVdwQWFmXzGzF83seTP7oZnVeV1TJkZGRigtLfW6DBGRnCu4oAD+CzjBOXcS8DLw\naY/ryUgkElGPQkSKUsEFhXPuP51zo6nF3wBHe1lPJhKJBNFoVD0KESlKBRcUE1wL/MzrIqYTiUQA\nFBQiUpQ8mRTQzB4Dlkyy6rPOuQdT23wWGAXumWIf64H1AM3NzXmqNDNjQaGhJxEpRp4EhXPuonTr\nzewa4DLgQuecm2IfG4ANAG1tbZNuM1fUoxCRYlZw04yb2aXA3wHnOeeGvK4nEyMjI4CCQkSKUyGe\no7gVqAb+y8x+b2a3e13QdDT0JCLFrOB6FM65lV7XkC0NPYlIMSvEHsW8o6EnESlmCooc0NCTiBQz\nBUUORCIRzIxQKOR1KSIiOaegyIGxCQE1xbiIFCMFRQ5EIhGdnxCRoqWgyAHNHCsixUxBkQOaOVZE\nipmCIgc09CQixUxBkQMaehKRYqagyAENPYlIMVNQzJJzTkNPIlLUFBSzFIvFSCQSCgoRKVoKilnS\n9B0iUuwUFLOkmWNFpNgpKGZpbOZY9ShEpFgpKGZJPQoRKXYKillSUIhIsVNQzJKGnkSk2CkoZkk9\nChEpdgqKWdJjUEWk2CkoZikSiRAOhwkE9K0UkeKkv26zpOk7RKTYZRQUZnaMmZWmPj/fzG4ws7r8\nljY/aOZYESl2mfYofgDEzWwlsAFYBnw3b1XNI5o5VkSKXaZBkXDOjQJvA77unPsUcFT+ygIz+4SZ\nOTNryOdxZktDTyJS7DINipiZvRN4H/BQ6r1QfkoCM1sG/DdgZ76OkSsjIyPqUYhIUcs0KN4PnAV8\n0Tm3w8xWAP+Wv7L4Z+DvAJfHY+SEehQiUuxKMtzuYufcDWMLqbAYyUdBZnYFsNs59wczy8chckpB\nISLFLtMexfsmee+amR7UzB4zsxcmeV0BfAb4fAb7WG9mm8xsU09Pz0xLmZV4PE4sFtPQk4gUtbQ9\nitR5iXcBK8zsx+NWVQP7Z3pQ59xFUxzvRGAFMNabOBr4nZmd6ZzbM2EfG0hegUVbW5snQ1SavkNE\n/GC6oadfA11AA/B/x71/CHg+18U457YAi8aWzawdaHPO7cv1sXJB03eIiB+kDQrnXAfQQfJEtkyg\nx6CKiB9kemf2lWa23cz6zKzfzA6ZWX++i3POtRRqbwI09CQi/pDpVU+3AJc757bls5j5RkNPIuIH\nmV71tFchcSQNPYmIH0x31dOVqU83mdm9wI+AyNh659wDeayt4GnoSUT8YLqhp8vHfT5EclqNMQ7w\ndVDoMagi4gfTXfX0/rkqZD6KRCIEg0FKSjI91SMiMv9k9BfOzP5lkrf7gE3OuQdzW9L8oek7RMQP\nMj2ZXQacAmxPvU4iedf0B8zsq3mqreBp5lgR8YNMx0xOAtY65+IAZnYb8EvgbGBLnmoreOpRiIgf\nZNqjWABUjVuuBBamgiMy+ZcUPwWFiPhBNjfc/d7MngQMOBe42cwqgcfyVFvBGxkZYeHChV6XISKS\nVxkFhXPuTjN7GDgz9dZnnHOvpz7/VF4qmweGh4cpLy/3ugwRkbxKO/RkZm9IfTyN5DOyd6VeS1Lv\n+ZZzTkEhIr4wXY/i48B6/nyK8TEOuCDnFc0TsViM0dFRKioqvC5FRCSvprvhbn3q47q5KWf+GBoa\nAlCPQkSKXqbTjFeY2efMbENqeZWZXZbf0grb8PAwgHoUIlL0Mr089ttAFHhzank38H/yUtE8oR6F\niPhFpkFxjHPuFiAG4JwbInmZrG+pRyEifpFpUETNrJzkCWzM7Bh8fKMdqEchIv6R6Q13XwAeAZaZ\n2T3AWuCafBU1H4z1KBQUIlLsMg2K9wE/Be4HXgM+WsjPsp4LQ0NDlJaWaopxESl6mf6VuxM4B7gY\nOAZ4zsx+4Zz7Wt4qK3BDQ0PqTYiIL2Q6hccTZvYL4AxgHfBh4HjAt0ExPDysE9ki4guZPrjo5yRn\njN1IcnrxM5xz3fksrNCpRyEifpHpVU/Pk7yP4gSSz6Y4IXUVlG+pRyEifpHp0NONAGZWTfJqp28D\nSwDfPoxBPQoR8YtMp/D4iJndCzwHXAHcBbwlX0WZ2d+a2YtmttXMbsnXcWYqHo8TiUTUoxARX8j0\nqqcy4P8Bm51zo3msBzNbRzKMTnbORcxsUT6PNxO6h0JE/CTToad/ynch41wHfNk5F0kdu+BOmo/d\nla0ehYj4QaYns+fSauAcM3vGzJ4yszO8LmgizfMkIn7iyW3FZvYYyZPhE32WZE0LgTeRvG/jPjNr\ndc65CftYT/KhSjQ3N+e34Ak0z5OI+IknQeGcu2iqdWZ2HfBAKhh+a2YJoAHombCPDcAGgLa2NnfE\njvJIPQoR8ZNCHHr6Ecm7vzGz1UAYKKh5pdSjEBE/KcQZ7e4C7jKzF0je5Pe+icNOXhseHiYYDBIO\nh70uRUQk7wouKJxzUeA9XteRztjNdma+fnaTiPhEIQ49FbyhoSGdnxAR31BQzMDw8LDOT4iIbygo\nZkA9ChHxEwXFDGjmWBHxEwVFlpxzGnoSEV9RUGQpEomQSCTUoxAR31BQZEk324mI3ygosqSZY0XE\nbxQUWdKzKETEbxQUWVKPQkT8RkGRJfUoRMRvFBRZ0slsEfEbBUWWxu6hCAT0rRMRf9BfuyyNzRwr\nIuIXCoosafoOEfEbBUWW1KMQEb9RUGRJM8eKiN8oKLIQi8U4dOgQtbW1XpciIjJnFBRZ6O3txTnH\nokWLvC5FRGTOKCiy0N3dDUBjY6PHlYiIzB0FRRa6u7sJBALU19d7XYqIyJxRUGShu7ub+vp6SkpK\nvC5FRGTOKCiy0NPTo/MTIuI7CooMRaNRDhw4oPMTIuI7BRcUZnaKmf3GzH5vZpvM7Eyva4JkbwJQ\nj0JEfKfgggK4BfhH59wpwOdTy54bu+JJQSEiflOIQeGAmtTntcDrHtZyWE9PD8FgkAULFnhdiojI\nnCrEy3c+BjxqZv9EMsje7HE9QLJH0dDQQDAY9LoUEZE55UlQmNljwJJJVn0WuBC40Tn3AzN7B3An\ncNEk+1gPrAdobm7OY7VJ3d3dLF++PO/HEREpNJ4EhXPuiD/8Y8zsO8BHU4vfB741xT42ABsA2tra\nXK5rHG9kZIT+/n6dnxARXyrEcxSvA+elPr8A2O5hLYCueBIRfyvEcxQfAr5mZiXACKnhJS/piicR\n8bOCCwrn3NPA6V7XMV53dzehUEjTi4uILxXi0FPB6enpobGxkUBA3y4R8R/95ctAd3e3hp1ExLcU\nFNPo7e1lYGCApUuXel2KiIgnFBTTePnllwFYuXKlx5WIiHhDQTGN7du309DQwMKFC70uRUTEEwqK\nNCKRCB0dHaxatcrrUkREPKOgSGPHjh3E43FWr17tdSkiIp5RUKTx8ssvEw6HWbZsmdeliIh4RkEx\nBecc27dv55hjjtEzskXE1xQUU9i7dy+HDh3SsJOI+J6CYgq6LFZEJElBMYXt27dz1FFHUV1d7XUp\nIiKeUlBMYnh4mM7OTl0WKyKCgmJSO3fuxDlHa2ur16WIiHhOQTGJ9vZ2gsEgTU1NXpciIuI5BcUk\nOjo6aGpqIhQKeV2KiIjnFBQTRCIRurq6aGlp8boUEZGCoKCYYOz8xPLly70uRUSkICgoJujo6CAQ\nCGjaDhGRFAXFBO3t7SxdupRwOOx1KSIiBUFBMU40GuX111/XsJOIyDgKinE6OztJJBI6kS0iMo6C\nYpz29nbMTOcnRETGUVCM09HRwZIlSygrK/O6FBGRgqGgSInFYnR2dmrYSURkAk+CwszebmZbzSxh\nZm0T1n3azF4xs5fM7JK5qmn37t3E43GdyBYRmcCrR7e9AFwJfHP8m2a2BrgKOB5YCjxmZqudc/F8\nF7Rz504Ampub830oEZF5xZMehXNum3PupUlWXQH8h3Mu4pzbAbwCnDkXNe3cuZPGxkYqKirm4nAi\nIvNGoZ2jaAJ2jVvuTL2XV4lEgl27dqk3ISIyibwNPZnZY8CSSVZ91jn3YA72vx5YD7MfLtq7dy+R\nSERBISIyibwFhXPuohl82W5g/E0MR6fem2z/G4ANAG1tbW4Gxzps7PyETmSLiByp0IaefgxcZWal\nZrYCWAX8Nt8H7ejooKamhrq6unwfSkRk3vHq8ti3mVkncBbwUzN7FMA5txW4D/gj8Ahwfb6veHLO\nsXPnTg07iYhMwZPLY51zPwR+OMW6LwJfnKtaDhw4wMDAgIadRESmUGhDT3Ouo6MD0P0TIiJT8X1Q\n7Ny5k7KyMhobG70uRUSkICkoUucnAgHffytERCbl67+OAwMD9Pb2athJRCQNXwdFX18ftbW1OpEt\nIpKGV5MCFoSmpiZuvPFGnJvV/XoiIkXN1z2KMWbmdQkiIgVLQSEiImkpKEREJC0FhYiIpKWgEBGR\ntBQUIiKSloJCRETSUlCIiEhaVgw3m5lZD9DhdR3TaAD2eV1EjhRLW4qlHaC2FKpCb8ty59y0M6IW\nRVDMB2a2yTnX5nUduVAsbSmWdoDaUqiKpS0aehIRkbQUFCIikpaCYu5s8LqAHCqWthRLO0BtKVRF\n0RadoxARkbTUoxARkbQUFCIikpaCQkRE0lJQFAAzazWzO83sfq9rydZ8rn0iMzvOzG43s/vN7Dqv\n65kNMzvfzH6Zas/5XtczU2Z2TqoN3zKzX3tdz2yY2Rozu8/MbjOzv/K6nmwoKGbJzO4ys24ze2HC\n+5ea2Utm9oqZ/X26fTjnXnPOfSC/lWYumzYVWu0TZdmWbc65DwPvANZ6UW86Wf6uOWAAKAM657rW\ndLL8mfwy9TN5CLjbi3rTyfJn8hbg686564D3znmxs+Gc02sWL+Bc4DTghXHvBYFXgVYgDPwBWAOc\nSPIXfvxr0bivu9/r9mTbpkKrfbZtAf4S+BnwLq9rn+XvWiC1fjFwj9e15+D36z6g2uvaZ/kzWQT8\nK/AV4Fde157NSz2KWXLO/QLYP+HtM4FXXPJ/21HgP4ArnHNbnHOXTXh1z3nR08imTXNeXJaybYtz\n7sfOubcA757bSqeX5e9aIrX+AFA6h2VOK9ufiZk1A33OuUNzW+n0svyZdDvnrgf+nsKe/+kICor8\naAJ2jVvuTL03KTOrN7PbgVPN7NP5Lm6GJm3TPKl9oqnacr6Z/YuZfRN42JvSsjZVW65MtePfgFs9\nqSw76f7NfAD49pxXNHNT/UxazGwD8B2SvYp5o8TrAgScc73Ah72uYybmc+0TOeeeBJ70uIyccM49\nADzgdR254Jz7gtc15IJzrh1Y73UdM6EeRX7sBpaNWz469d58VkxtUlsKT7G0A4qrLYCCIl+eBVaZ\n2QozCwNXAT/2uKbZKqY2qS2Fp1jaAcXVFkBBMWtm9j1gI3CsmXWa2Qecc6PAR4BHgW3Afc65rV7W\nmY1iapPaUniKpR1QXG1JR5MCiohIWupRiIhIWgoKERFJS0EhIiJpKShERCQtBYWIiKSloBARkbQU\nFCKzZGbtZtYw221ECpWCQkRE0lJQiGTBzH5kZpvNbKuZrZ+wrsXMXjSze8xsW+pJeRXjNvlbM/ud\nmW0xszekvuZMM9toZs+Z2a/N7Ng5bZBIBhQUItm51jl3OtAG3GBm9RPWHwt8wzl3HNAP/M24dfuc\nc6cBtwGfTL33InCOc+5U4PPAzXmtXmQGFBQi2bnBzP4A/IbkDKGrJqzf5Zz7VerzfwfOHrdubNrv\nzUBL6vNa4PupR2n+M3B8PooWmQ0FhUiGzOx84CLgLOfcycBzJJ9JPd7EydPGL0dSH+P86Vkw/xt4\nwjl3AnD5JPsT8ZyCQiRztcAB59xQ6hzDmybZptnMzkp9/i7g6Qz2OfasgmtyUqVIjikoRDL3CFBi\nZtuAL5McfproJeD61DYLSJ6PSOcW4Etm9hx64qQUKE0zLpIjZtYCPJQaRhIpGupRiIhIWupRiIhI\nWupRiIhIWgoKERFJS0EhIiJpKShERCQtBYWIiKSloBARkbT+P2OfBBW1tE0NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xffd99e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso = Lasso(random_state=0, normalize=True)\n",
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "n_folds = 5\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas*2, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the lasso regression The Coef.'s go to 0 relatively quickly for a small lambda. This means that the model will be similar to the OLS model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xb817ef0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEOCAYAAACuOOGFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdac47b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge = Ridge(random_state=0, normalize= True)\n",
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "n_folds = 5\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha=a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas*2, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Ridge regression model has a larger lambda than the lasso regression with the coef. converging to 0. This means that the model is getting further away from the normal OLS model and is able to shrink the coef. more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For both of the plots as lambda increases, the coef. of both models either reach 0 (for lasso) or converge to 0 (for ridge). This is because lambda is shrinks the ceof.'s to prevent overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 17.30\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Ridge regression does better than the lasso regression but worse than the ridge regression. which indicates there is a need for a shrinkage parameter and that not all the variables contain meaningful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso=linear_model.Lasso(alpha=lasso_param['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.442277528608152"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_fit=lasso.fit(X_train, y_train)\n",
    "y_pred=lasso_fit.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lasso regression has the worst MSE compared to the ridge and ols regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ridge=linear_model.Ridge(alpha=ridge_param['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.296581808941255"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_fit=Ridge.fit(X_train, y_train)\n",
    "y_pred=ridge_fit.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Ridge regression does has the best MSE. This is likley because while the ridge regression shrinks the paramaters of the model, it still uses information from the other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.697274102647892"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso=LassoCV(fit_intercept = True,alphas=None, cv=10, max_iter=10000, normalize= True)\n",
    "lasso_fit=lasso.fit(X_train, y_train)\n",
    "y_pred=lasso_fit.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once the new variables were added into the model the Lasso regression had a much better MSE. This is likley due to the added variables bringing in new information for the model to learn from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00093788910649581739"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_fit.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lambda reported from the model is shown above and is very small, the lasso model doesnt need to shrink the coef. that much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.49113328e-01,  -0.00000000e+00,   0.00000000e+00,\n",
       "         2.70670946e-01,  -0.00000000e+00,  -1.44385364e+01,\n",
       "         0.00000000e+00,  -1.88299123e+00,   2.16262671e-01,\n",
       "        -9.81882271e-03,  -6.87148708e-01,   6.19870400e-03,\n",
       "        -1.30043499e+00,  -0.00000000e+00,   8.05627266e-05,\n",
       "         1.84664901e-03,   1.24184100e+00,  -1.49491505e+01,\n",
       "         1.42332158e+00,   1.31847963e-04,   9.03783102e-02,\n",
       "         0.00000000e+00,  -0.00000000e+00,   0.00000000e+00,\n",
       "        -0.00000000e+00,   2.22539347e-02])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_fit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.149113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.270671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>-14.438536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.882991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.216263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.009819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.687149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.006199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-1.300435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1\n",
       "0                 \n",
       "CRIM     -0.149113\n",
       "ZN       -0.000000\n",
       "INDUS     0.000000\n",
       "CHAS      0.270671\n",
       "NOX      -0.000000\n",
       "RM      -14.438536\n",
       "AGE       0.000000\n",
       "DIS      -1.882991\n",
       "RAD       0.216263\n",
       "TAX      -0.009819\n",
       "PTRATIO  -0.687149\n",
       "B         0.006199\n",
       "LSTAT    -1.300435"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame((zip(features, lasso_fit.coef_))).set_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the lasso regression estimated coef, INDUS, ZN, and NOX contain no information for the response variable and were shrunk to 0 by the lasso model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5  (5 pts)\n",
    "\n",
    "A regression model that includes \"interaction terms\" (i.e. quadratic terms of the form $x_ix_j$) as predictors in addition to the linear terms is clearly more general than a corresponding model that employs the same independent variables but only uses the linear terms. Outline two situations where the simpler (less general) model would be preferred to the more powerful model that includes interactive terms.\n",
    "\n",
    "## Answer\n",
    "\n",
    "1: If the data were fit perfectly by a linear approxamation adding interaction terms to the model would only increase the variance of the model, with no significant decrease in bias. An example might be years of education as an undergraduate and total amount paid in tuition. \n",
    "\n",
    "2: If the data were extermely noisy, adding more interaction terms might be just 'chasing noise'. An example might be predicting stock market prices. If you fit the data really well with a complicated model you will likley just be chasing the noise of the stock market and wont make good predictions out of sample. A much simplier model would be suffice to adequetly predict stock market prices, like yesterdays stock price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
