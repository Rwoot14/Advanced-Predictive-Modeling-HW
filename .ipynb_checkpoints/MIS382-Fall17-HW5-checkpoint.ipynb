{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align: center;\">MIS382: Advanced Predictive Modeling</p>\n",
    "# <p style=\"text-align: center;\">Assignment 5</p>\n",
    "## <p style=\"text-align: center;\">Total points: 35</p>\n",
    "## <p style=\"text-align: center;\">Due: Monday, November 27th, submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group.  \n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Ensembles (1+12+2 = 15pts)\n",
    "In this question, we will compare performance of different ensemble methods: [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (GBDT), and [XGBoost](http://xgboost.readthedocs.io/en/latest/).  Note that you have to install xgboost package in addition to scikit-learn.  You can see installation guides [here](http://xgboost.readthedocs.io/en/latest/build.html).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Two  datasets are provided for this problem. For **each of the datasets ((X1.csv, y1.csv), (X2.csv, y2.csv))**, do the following:\n",
    "\n",
    "1. Load the data and partition it into features (X) and the target label (y) for classification task. Then, use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and testing: test_size=0.33, random_state=42.\n",
    "\n",
    "2. Build a classifier using [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), and [XGBoost](http://xgboost.readthedocs.io/en/latest/), respectively, and answer the following for each classifier.\n",
    "\n",
    " - Mention any design choices (with reasoning/justification) that you made, e.g. the hyperparameters considered for each classifier.\n",
    " - Report the mean error rate (fraction of incorrect labels) and the confusion matrix on test data. <br>\n",
    " - Report the feature importance and time of execution (training and predicting times).\n",
    "\n",
    "3. Compare the three classifiers for the two different datasets ((X1.csv, y1.csv), (X2.csv, y2.csv)) in terms of the misclassification rate.  What are the characteristics of the dataset and the classifiers that resulted in somewhat different comparative results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ReeceWooten/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=pd.read_csv('/Users/ReeceWooten/Documents/School /MSBA/Fall/Adv.Predictive/hmk5_data/X1.csv',header=None)\n",
    "X2=pd.read_csv('/Users/ReeceWooten/Documents/School /MSBA/Fall/Adv.Predictive/hmk5_data/X2.csv',header=None)\n",
    "y1=pd.read_csv('/Users/ReeceWooten/Documents/School /MSBA/Fall/Adv.Predictive/hmk5_data/y1.csv',header=None)\n",
    "y2=pd.read_csv('/Users/ReeceWooten/Documents/School /MSBA/Fall/Adv.Predictive/hmk5_data/y2.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (X1.csv, y1.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best Parameters: {'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "params={'n_estimators':[100,500,1000]}\n",
    "random_for=RandomForestClassifier(n_jobs=-1,random_state=42)\n",
    "clf=GridSearchCV(random_for, params)\n",
    "fit=clf.fit(X=X_train,y=y_train.values.ravel())\n",
    "pred=fit.predict(X_test)\n",
    "print 'best Parameters:', fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 10.2630000114\n",
      "Feature Importance: [ 0.04431502  0.01433167  0.01412465  0.01430413  0.01474061  0.01451441\n",
      "  0.01504657  0.01522581  0.01404021  0.01448577  0.01478121  0.01413298\n",
      "  0.01507971  0.01388314  0.01473862  0.01436213  0.01429501  0.01450129\n",
      "  0.06266232  0.01430806  0.01482966  0.09657533  0.42067637  0.01417478\n",
      "  0.01435882  0.01382586  0.01439905  0.01467517  0.01438618  0.01422543]\n"
     ]
    }
   ],
   "source": [
    "random_for=RandomForestClassifier(n_jobs=-1,random_state=42,n_estimators=1000)\n",
    "t0=time()\n",
    "fit=random_for.fit(X=X_train,y=y_train.values.ravel())\n",
    "pred=fit.predict(X_test)\n",
    "print 'Time Taken:',time()-t0\n",
    "print 'Feature Importance:', fit.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1433,  248],\n",
       "       [ 152, 1467]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confus=confusion_matrix(y_pred=pred,y_true=y_test)\n",
    "confus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error Rate: 0.121212121212\n"
     ]
    }
   ],
   "source": [
    "print 'Mean Error Rate:',(confus[0][1]+confus[1][0])/float(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (X2.csv, y2.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best Parameters: {'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "params={'n_estimators':[100,500,1000]}\n",
    "random_for=RandomForestClassifier(n_jobs=-1,random_state=42)\n",
    "clf=GridSearchCV(random_for, params)\n",
    "fit=clf.fit(X=X2_train,y=y2_train.values.ravel())\n",
    "pred=fit.predict(X2_test)\n",
    "print 'best Parameters:', fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance: [ 0.02896598  0.01699222  0.01619105  0.05564484  0.05335792  0.0591138\n",
      "  0.04776768  0.056298    0.04464193  0.14732021  0.03613252  0.08334729\n",
      "  0.01564104  0.06610192  0.01624294  0.06865922  0.05177554  0.0165388\n",
      "  0.07981951  0.03944759]\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "random_for=RandomForestClassifier(n_jobs=-1,random_state=42,n_estimators=1000)\n",
    "fit=random_for.fit(X=X2_train,y=y2_train.values.ravel())\n",
    "pred=fit.predict(X2_test)\n",
    "print 'Time Taken:',time()-t0\n",
    "print 'Feature Importance:', fit.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[784,  66],\n",
       "       [ 35, 765]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confus=confusion_matrix(y_pred=pred,y_true=y2_test)\n",
    "confus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error Rate: 0.0306060606061\n"
     ]
    }
   ],
   "source": [
    "print 'Mean Error Rate:',(confus[0][1]+confus[1][0])/float(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (X1.csv, y1.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 313.991631031\n",
      "best Parameters: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "t0=time()\n",
    "params={'max_depth':[1,2,3],'learning_rate':[.001,.01,.1],'n_estimators':[500,1000]}\n",
    "grad=GradientBoostingClassifier(random_state=42)\n",
    "clf=GridSearchCV(grad, params)\n",
    "fit=clf.fit(X=X_train,y=y_train.values.ravel())\n",
    "print 'Time Taken:',time()-t0\n",
    "print 'best Parameters:', fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 15.3645939827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0544251 ,  0.01917306,  0.02850817,  0.0292458 ,  0.02901202,\n",
       "        0.02837113,  0.03308446,  0.03630208,  0.02287203,  0.03131862,\n",
       "        0.02270644,  0.02459479,  0.03241855,  0.02237735,  0.02996814,\n",
       "        0.02395729,  0.02883544,  0.02663355,  0.05859324,  0.02359324,\n",
       "        0.02788738,  0.07085674,  0.09011325,  0.02471198,  0.03253809,\n",
       "        0.03168191,  0.02510279,  0.02526566,  0.02671365,  0.03913805])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time()\n",
    "grad1=GradientBoostingClassifier(max_depth=3,learning_rate=.1,n_estimators=1000)\n",
    "fit=grad1.fit(X=X_train,y=y_train.values.ravel())\n",
    "pred=fit.predict(X_test)\n",
    "print 'Time Taken:',time()-t0\n",
    "fit.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1499,  182],\n",
       "       [ 141, 1478]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confus=confusion_matrix(y_pred=pred,y_true=y_test)\n",
    "confus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error Rate: 0.195757575758\n"
     ]
    }
   ],
   "source": [
    "print 'Mean Error Rate:',(confus[0][1]+confus[1][0])/float(len(y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (X2.csv, y2.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 111.793998957\n",
      "best Parameters: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "t0=time()\n",
    "params={'max_depth':[1,2,3],'learning_rate':[.001,.01,.1],'n_estimators':[500,1000]}\n",
    "grad2=GradientBoostingClassifier(random_state=42)\n",
    "clf2=GridSearchCV(grad2, params)\n",
    "fit2=clf2.fit(X=X2_train,y=y2_train.values.ravel())\n",
    "print 'Time Taken:',time()-t0\n",
    "print 'best Parameters:', fit2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05122169,  0.03045946,  0.02431011,  0.06181678,  0.06379853,\n",
       "        0.04765492,  0.04572279,  0.06876345,  0.04984366,  0.06439279,\n",
       "        0.05048733,  0.06456411,  0.01997549,  0.05266167,  0.02340354,\n",
       "        0.07135562,  0.05588212,  0.02688073,  0.07484439,  0.05196082])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad2=GradientBoostingClassifier(max_depth=3,learning_rate=.1,n_estimators=1000)\n",
    "fit2=grad2.fit(X=X2_train,y=y2_train.values.ravel())\n",
    "pred2=fit2.predict(X2_test)\n",
    "fit2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[789,  61],\n",
       "       [ 32, 768]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confus2=confusion_matrix(y_pred=pred2,y_true=y2_test)\n",
    "confus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error Rate: 0.0563636363636\n"
     ]
    }
   ],
   "source": [
    "print 'Mean Error Rate:',(confus2[0][1]+confus2[1][0])/float(len(y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (X1.csv, y1.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 108.996088028\n",
      "best Parameters: {'max_depth': 7, 'gamma': 1, 'min_child_weight': 2}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "t0=time()\n",
    "params={'max_depth':[5,6,7],'min_child_weight':[1,2,3],'gamma':[0,1,2]}\n",
    "grad3=XGBClassifier()\n",
    "clf3=GridSearchCV(grad3, params)\n",
    "fit3=clf3.fit(X=X_train,y=y_train.values.ravel())\n",
    "print 'Time Taken:',time()-t0\n",
    "print 'best Parameters:', fit3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 2.37207388878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.12555929,  0.02516779,  0.01454139,  0.01957494,  0.02013423,\n",
       "        0.01649888,  0.01649888,  0.02880313,  0.01482103,  0.01565995,\n",
       "        0.0159396 ,  0.01845638,  0.02488814,  0.00978747,  0.01510067,\n",
       "        0.0192953 ,  0.01621924,  0.02041387,  0.16219239,  0.01845638,\n",
       "        0.02181208,  0.13422818,  0.0950783 ,  0.01677852,  0.01538031,\n",
       "        0.01677852,  0.02376957,  0.02041387,  0.02097316,  0.01677852], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time()\n",
    "model = XGBClassifier(max_depth=7,min_child_weight=2,gamma=1)\n",
    "fit=model.fit(X_train, y_train.values.ravel())\n",
    "pred=fit.predict(X_test)\n",
    "print 'Time Taken:',time()-t0\n",
    "fit.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1526,  155],\n",
       "       [ 109, 1510]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confus=confusion_matrix(y_pred=pred,y_true=y_test)\n",
    "confus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error Rate: 0.08\n"
     ]
    }
   ],
   "source": [
    "print 'Mean Error Rate:',(confus[0][1]+confus[1][0])/float(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (X2.csv, y2.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 37.8252789974\n",
      "best Parameters: {'max_depth': 7, 'gamma': 0, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "t0=time()\n",
    "params={'max_depth':[5,6,7],'min_child_weight':[1,2,3],'gamma':[0,1,2]}\n",
    "grad3=XGBClassifier()\n",
    "clf3=GridSearchCV(grad3, params)\n",
    "fit3=clf3.fit(X=X2_train,y=y2_train.values.ravel())\n",
    "print 'Time Taken:',time()-t0\n",
    "print 'best Parameters:', fit3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 0.775943040848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.04911092,  0.01714649,  0.01439458,  0.0607536 ,  0.06223539,\n",
       "        0.06879763,  0.05546147,  0.06583404,  0.05609653,  0.0592718 ,\n",
       "        0.0522862 ,  0.07281964,  0.01587638,  0.06710415,  0.01164268,\n",
       "        0.07049111,  0.06456393,  0.01820491,  0.07006774,  0.04784081], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time()\n",
    "model = XGBClassifier(max_depth=7,min_child_weight=1,gamma=0)\n",
    "fit=model.fit(X2_train, y2_train.values.ravel())\n",
    "pred=fit.predict(X2_test)\n",
    "print 'Time Taken:',time()-t0\n",
    "fit.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[782,  68],\n",
       "       [ 39, 761]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confus=confusion_matrix(y_pred=pred,y_true=y2_test)\n",
    "confus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error Rate: 0.0324242424242\n"
     ]
    }
   ],
   "source": [
    "print 'Mean Error Rate:',(confus[0][1]+confus[1][0])/float(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Visualization using Bokeh (10 pts)\n",
    "\n",
    "In this problem, you'll build an interactive visualization. Bokeh is a Python interactive visualization library that targets modern web browsers for presentation. For more information on Bokeh, see http://bokeh.pydata.org/en/latest/. The problem statement is as follows:\n",
    "\n",
    "Using the \"nbasalariesfull.csv\" data set from HMK4, your goal is to build a Bokeh visualization which allows the user to explore how salary (on a log scale) varies with points per game (PSG) and age. You will create a visualization that allows the user to toggle the X axis of a scatter plot between PSG and age, with the y-axis always being log Salary. Also add the hover tool so that if the user hovers over a datapoint in the plot a window pops up that shows the player name, team, position, salary, and the current x variable (PSG or age) depending on the current tab.  Color each point according to a player's position and provide a legend for the colors. Add the ability to Zoom in/out.  Add slight horizontal jitter to a player's age.\n",
    "\n",
    "Hints: \n",
    "1. see: http://bokeh.pydata.org/en/latest/docs/user_guide/tools.html#basic-tooltips for hover and zoom tool examples.\n",
    "2. See: http://bokeh.pydata.org/en/latest/docs/reference/plotting.html. Look for the scatter API.\n",
    "3. See: http://bokeh.pydata.org/en/0.10.0/docs/user_guide/styling.html#labels. For labeling axes.\n",
    "4. See: https://bokeh.pydata.org/en/latest/docs/user_guide/categorical.html  for how to use jitter transform\n",
    "5. See: http://bokeh.pydata.org/en/latest/docs/gallery/iris.html for coloring points by category\n",
    "6. Use output_notebook() from Bokeh to output the plot to your notebook\n",
    "\n",
    "Include an image screenshot in addition to the visualization output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "from bokeh.models import CustomJS, ColumnDataSource, HoverTool, BoxZoomTool\n",
    "from bokeh.models.transforms import Jitter\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.models import Legend,LegendItem\n",
    "\n",
    "data = pd.read_csv(\"/Users/ReeceWooten/Documents/School /MSBA/Fall/Adv.Predictive/hmk5_data/nbasalariesfull.csv\")\n",
    "data[\"logsalary\"] = data.SALARY.apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Toggle x axis: PSG and age (check)\n",
    "\n",
    "2: Hover over data point shows the player name, team, position, salary, and the current x variable (PSG or age)\n",
    "\n",
    "3: Color each point according to a player's position and provide a legend for the colors\n",
    "\n",
    "4: Add the ability to Zoom in/out\n",
    "\n",
    "5: Add slight horizontal jitter to a player's age.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>...</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PSG</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>logsalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>PG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.504</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>11370786</td>\n",
       "      <td>16.246558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Player   Tm Pos   Age     G    GS    MP    FG   FGA    FG%  \\\n",
       "0  Stephen Curry  GSW  PG  27.0  79.0  79.0  34.2  10.2  20.2  0.504   \n",
       "\n",
       "     ...      DRB  TRB  AST  STL  BLK  TOV   PF   PSG    SALARY  logsalary  \n",
       "0    ...      4.6  5.4  6.7  2.1  0.2  3.3  2.0  30.1  11370786  16.246558  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_list=list(data['Pos'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clears Figure history\n",
    "from bokeh.io import curdoc\n",
    "curdoc().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=ColumnDataSource(data)\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"index\", \"$index\"),\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"Player\", \"@Player\"),\n",
    "    (\"Team\", \"@Tm\"),\n",
    "    (\"Position\", \"@Pos\"),\n",
    "    (\"Salary\", \"@SALARY\"),\n",
    "])\n",
    "\n",
    "hover2 = HoverTool(tooltips=[\n",
    "    (\"index\", \"@index\"),\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"Player\", \"@Player\"),\n",
    "    (\"Team\", \"@Tm\"),\n",
    "    (\"Position\", \"@Pos\"),\n",
    "    (\"Salary\", \"@SALARY\"),\n",
    "])\n",
    "\n",
    "\n",
    "colormap = {'PF': 'red', 'PG': 'green', 'SF': 'blue','SG':'brown','C':'black','PF-C':'grey','SG-SF':'purple'}\n",
    "colors = [colormap[x] for x in data['Pos']]\n",
    "\n",
    "fig1=figure(title='Age Vs. Log_salary',tools=[hover,'wheel_zoom'])\n",
    "fig1.xaxis.axis_label = 'Age'\n",
    "fig1.yaxis.axis_label = 'Log_salary'\n",
    "fig1.circle(y='logsalary',x={'field':'Age','transform':Jitter(width=1)},source=source, fill_alpha=0.2, size=10,color=colors,legend='Pos')\n",
    "\n",
    "tab1=Panel(child=fig1,title='Age')\n",
    "\n",
    "fig2=figure(title='PSG Vs. Log_salary',tools=[hover2,'wheel_zoom'])\n",
    "fig2.xaxis.axis_label = 'PSG'\n",
    "fig2.yaxis.axis_label = 'Log_salary'\n",
    "fig2.circle(y='logsalary',x='PSG',source=source, fill_alpha=0.2, size=10,color=colors,legend='Pos')\n",
    "tab2=Panel(child=fig2,title='PSG Vs. Log_salary')\n",
    "\n",
    "tabs=Tabs(tabs=[tab1,tab2])\n",
    "show(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Diabetes classification using support vector machines (4+3+3=10 pts) \n",
    "(a) Apply a linear SVM, using the scikit-SVM, for the Pima Indian Women diabetes detection problem on the dataset provided (details on dataset here  http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes) . Specify how you chose the slack cost/penalty (‘C’ parameter)for the model. Maintain all other parameters as default. Hint: http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html will make 10-fold cross-validation easier.\n",
    "The code to get the training/testing data is provided below.\n",
    "\n",
    "(b) Repeat (a) but using a Gaussian radial basis kernel.\n",
    "\n",
    "(c) Summarize the comparative performance (mean error rates) of the classifiers. What do you conclude? (be brief)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import grid_search\n",
    "\n",
    "data_train = pd.read_csv('diabetes_train-log.csv')\n",
    "data_test = pd.read_csv('diabetes_test-log.csv')\n",
    "cols = ['numpreg', 'plasmacon', 'bloodpress', 'skinfold', 'seruminsulin', 'BMI', 'pedigreefunction', 'age']\n",
    "\n",
    "xtrain = np.asmatrix(data_train[cols])\n",
    "ytrain = np.asarray(data_train['classvariable']).T\n",
    "\n",
    "xtest = np.asmatrix(data_test[cols])\n",
    "ytest = np.asarray(data_test['classvariable']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
